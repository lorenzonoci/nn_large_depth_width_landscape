{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b2861a37-4958-48ad-8ef4-f9b35ef5d702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TwoLayerModel(\n",
      "  (layer1): Linear(in_features=10, out_features=5, bias=False)\n",
      "  (layer2): Linear(in_features=5, out_features=1, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the model\n",
    "class TwoLayerModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(TwoLayerModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size, bias=False)\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "input_size = 10\n",
    "hidden_size = 5\n",
    "output_size = 1\n",
    "\n",
    "model = TwoLayerModel(input_size, hidden_size, output_size)\n",
    "print(model)\n",
    "\n",
    "model = TwoLayerModel(input_size, hidden_size, output_size)\n",
    "\n",
    "# Generate some dummy data\n",
    "inputs1 = torch.randn(1, input_size)\n",
    "inputs2 = torch.randn(1, input_size)\n",
    "inputs = torch.cat([inputs1, inputs2], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "dad6e17e-e8aa-4714-928c-f7586935dcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6454, grad_fn=<SqueezeBackward0>) tensor(3.2474, grad_fn=<SqueezeBackward0>) tensor(3.6465, grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# compute ntk with torch for sanity\n",
    "from functorch import make_functional, vmap, vjp, jvp, jacrev\n",
    "fnet, params = make_functional(model)\n",
    "def fnet_single(params, x):\n",
    "    return fnet(params, x.unsqueeze(0)).squeeze(0)\n",
    "def empirical_ntk_jacobian_contraction(fnet_single, params, x1, x2):\n",
    "    # Compute J(x1)\n",
    "    jac1 = vmap(jacrev(fnet_single), (None, 0))(params, x1)\n",
    "    jac1 = [j.flatten(2) for j in jac1]\n",
    "    \n",
    "    # Compute J(x2)\n",
    "    jac2 = vmap(jacrev(fnet_single), (None, 0))(params, x2)\n",
    "    jac2 = [j.flatten(2) for j in jac2]\n",
    "    \n",
    "    # Compute J(x1) @ J(x2).T\n",
    "    result = torch.stack([torch.einsum('Naf,Mbf->NMab', j1, j2) for j1, j2 in zip(jac1, jac2)])\n",
    "    result = result.sum(0)\n",
    "    return result\n",
    "m12 = empirical_ntk_jacobian_contraction(fnet_single, params, inputs1, inputs2).squeeze().flatten()\n",
    "m11 = empirical_ntk_jacobian_contraction(fnet_single, params, inputs1, inputs1).squeeze().flatten()\n",
    "m22 = empirical_ntk_jacobian_contraction(fnet_single, params, inputs2, inputs2).squeeze().flatten()\n",
    "print(m12, m11, m22)\n",
    "\n",
    "# print(torch.linalg.eigvalsh(result), torch.linalg.eigvalsh(result).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d4dfee3e-b821-46bd-9d67-b32e2477c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Forward pass\n",
    "# model.zero_grad()\n",
    "# outputs = model(inputs1)\n",
    "# gradients = torch.autograd.grad(outputs, model.parameters(), grad_outputs=torch.ones_like(outputs), create_graph=True)\n",
    "# print(gradients[0].shape, gradients[1].shape)\n",
    "# flattened_gradients1 = torch.cat([grad.view(-1) for grad in gradients])\n",
    "\n",
    "# # Forward pass\n",
    "# model.zero_grad()\n",
    "# outputs = model(inputs2)\n",
    "# gradients = torch.autograd.grad(outputs, model.parameters(), grad_outputs=torch.ones_like(outputs), create_graph=True)\n",
    "# flattened_gradients2 = torch.cat([grad.view(-1) for grad in gradients])\n",
    "\n",
    "# m11 = flattened_gradients1@flattened_gradients1\n",
    "# m22 = flattened_gradients2@flattened_gradients2\n",
    "# m12 = flattened_gradients1@flattened_gradients2\n",
    "# ntk_matrix = torch.tensor([[m11, m12], [m12, m22]])\n",
    "# print(ntk_matrix)\n",
    "\n",
    "# print(torch.linalg.eigvalsh(ntk_matrix).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f1320c11-a04f-4a72-9d42-d06966f76647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(17.7620, grad_fn=<SumBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "ntk_eigenvalues = kernel_eigenvalues(model, inputs, cross_entropy=False, print_progress=False, top_n=1, tol=1e-6)\n",
    "print(ntk_eigenvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ce3332-bd74-4790-ab90-c6fc3ee951fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
